@inproceedings{yu2022infinite,
  title={Infinite mixture chaining: Efficient temporal construction of word meaning},
  author={Yu, Lei and Xu, Yang},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={44},
  number={44},
  year={2022}
}

@inproceedings{yu2020nouns,
  title={How nouns surface as verbs: Inference and generation in word class conversion},
  author={Yu, Lei and Sanyoura, Lana El and Xu, Yang},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={42},
  year={2020}
}

@article{yu2024functional,
  title={Functional faithfulness in the wild: Circuit discovery with differentiable computation graph pruning},
  author={Yu, Lei and Niu, Jingcheng and Zhu, Zining and Penn, Gerald},
  journal={arXiv preprint arXiv:2407.03779},
  year={2024}
}

@article{tanchip2020inferring,
  title={Inferring symmetry in natural language},
  author={Tanchip, Chelsea and Yu, Lei and Xu, Aotao and Xu, Yang},
  journal={arXiv preprint arXiv:2010.08090},
  year={2020}
}

@article{fugikawa2023computational,
  title={A computational analysis of crosslinguistic regularity in semantic change},
  author={Fugikawa, Olivia and Hayman, Oliver and Liu, Raymond and Yu, Lei and Brochhagen, Thomas and Xu, Yang},
  journal={Frontiers in Communication},
  volume={8},
  pages={1136338},
  year={2023},
  publisher={Frontiers Media SA}
}

@article{yu2023word,
  title={Word sense extension},
  author={Yu, Lei and Xu, Yang},
  journal={arXiv preprint arXiv:2306.05609},
  year={2023}
}

@article{yu2022noun2verb,
  title={Noun2Verb: Probabilistic frame semantics for word class conversion},
  author={Yu, Lei and Xu, Yang},
  journal={Computational Linguistics},
  volume={48},
  number={4},
  pages={783--818},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@article{yu2021predicting,
  title={Predicting emergent linguistic compositions through time: Syntactic frame extension via multimodal chaining},
  author={Yu, Lei and Xu, Yang},
  journal={arXiv preprint arXiv:2109.04652},
  year={2021}
}

@article{cao2024drlc,
  title={Drlc: Reinforcement learning with dense rewards from llm critic},
  author={Cao, Meng and Shu, Lei and Yu, Lei and Zhu, Yun and Wichers, Nevan and Liu, Yinxiao and Meng, Lei},
  journal={arXiv e-prints},
  pages={arXiv--2401},
  year={2024}
}

@article{yu2024mechanisms,
  title={Mechanisms of non-factual hallucinations in language models},
  author={Yu, Lei and Cao, Meng and Kit Cheung, Jackie Chi and Dong, Yue},
  journal={arXiv e-prints},
  pages={arXiv--2403},
  year={2024}
}

@article{hong2024intrinsic,
  title={Intrinsic evaluation of unlearning using parametric knowledge traces},
  author={Hong, Yihuai and Yu, Lei and Yang, Haiqin and Ravfogel, Shauli and Geva, Mor},
  journal={arXiv preprint arXiv:2406.11614},
  year={2024}
}

@article{yu2023systematic,
  title={Systematic word meta-sense extension},
  author={Yu, Lei},
  journal={arXiv preprint arXiv:2311.13029},
  year={2023}
}

@article{cheng2024emergence,
  title={Emergence of a high-dimensional abstraction phase in language transformers},
  author={Cheng, Emily and Doimo, Diego and Kervadec, Corentin and Macocco, Iuri and Yu, Jade and Laio, Alessandro and Baroni, Marco},
  journal={arXiv preprint arXiv:2405.15471},
  year={2024}
}

@article{lee2024geometric,
  title={Geometric Signatures of Compositionality Across a Language Model's Lifetime},
  author={Lee, Jin Hwa and Jiralerspong, Thomas and Yu, Lei and Bengio, Yoshua and Cheng, Emily},
  journal={arXiv preprint arXiv:2410.01444},
  year={2024}
}

@article{yu2024robust,
  title={Robust LLM safeguarding via refusal feature adversarial training},
  author={Yu, Lei and Do, Virginie and Hambardzumyan, Karen and Cancedda, Nicola},
  journal={arXiv preprint arXiv:2409.20089},
  year={2024}
}

@article{yu2024mechanistic,
  title={Mechanistic understanding and mitigation of language model non-factual hallucinations},
  author={Yu, Lei and Cao, Meng and Cheung, Jackie Chi Kit and Dong, Yue},
  journal={arXiv preprint arXiv:2403.18167},
  year={2024}
}

@inproceedings{cao2024enhancing,
  title={Enhancing reinforcement learning with dense rewards from language model critic},
  author={Cao, Meng and Shu, Lei and Yu, Lei and Zhu, Yun and Wichers, Nevan and Liu, Yinxiao and Meng, Lei},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={9119--9138},
  year={2024}
}

@article{tao2023rolecraft,
  title={Rolecraft-glm: Advancing personalized role-playing in large language models},
  author={Tao, Meiling and Liang, Xuechen and Shi, Tianyu and Yu, Lei and Xie, Yiting},
  journal={arXiv preprint arXiv:2401.09432},
  year={2023}
}

@inproceedings{jiralerspong2024geometric,
  title={Geometric Signatures of Compositionality in Language Models},
  author={Jiralerspong, Thomas and Lee, Jin Hwa and Yu, Lei and Cheng, Emily},
  booktitle={NeurIPS 2024 Workshop on Compositional Learning: Perspectives, Methods, and Paths Forward}
}

@article{yu2025infinite,
  title={Infinite Mixture Chaining: An Efficiency-Based Framework for the Dynamic Construction of Word Meaning},
  author={Yu, Lei and Xu, Yang},
  journal={Open Mind},
  volume={9},
  pages={1--24},
  year={2025},
  publisher={MIT Press}
}

@article{cao2024beyond,
  title={Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation},
  author={Cao, Meng and Shu, Lei and Yu, Lei and Zhu, Yun and Wichers, Nevan and Liu, Yinxiao and Meng, Lei},
  journal={arXiv preprint arXiv:2401.07382},
  year={2024}
}

@article{hongreasoning,
  title={The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction},
  author={Hong, Yihuai and Zhou, Dian and Cao, Meng and Yu, Lei and Jin, Zhijing}
}

@article{ji2025calibrating,
  title={Calibrating Verbal Uncertainty as a Linear Feature to Reduce Hallucinations},
  author={Ji, Ziwei and Yu, Lei and Koishekenov, Yeskendir and Bang, Yejin and Hartshorn, Anthony and Schelten, Alan and Zhang, Cheng and Fung, Pascale and Cancedda, Nicola},
  journal={arXiv preprint arXiv:2503.14477},
  year={2025}
}
